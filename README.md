

# ğŸ›ï¸ **Product Review Analyzer & Recommender System**


<p align="left">
  <img src="images/rubiks-cool.gif" alt="rubiks-cool" width="100"/>
</p>

### *An AI-Powered MLOps Project for Scalable Product Intelligence*

> âš™ï¸ **Milestone-1:** *From Notebook â†’ Reproducible Repository*
> ğŸ¯ **Next (Milestone-2):** *LLMOps Integration â€” Personalized Review Generation with Large Language Models*

![Banner](images/logo.png)

---

## ğŸš€ **Elevator Pitch**

Welcome to **Product Review Analyzer**, an **end-to-end MLOps project** that turns **raw Amazon-style reviews** into actionable intelligence ğŸ”.
Our system builds an **Itemâ€“Item Collaborative Filtering recommender**, tracks it through **MLflow**, monitors it via **Prometheus + Grafana**, and checks for **data drift using Evidently** â€” all served through a **FastAPI microservice**.

ğŸ’¡ In **Milestone-2 (LLMOps Phase)**, weâ€™ll integrate **LLMs** to:

* ğŸ§  Generate **personalized product summaries**.
* ğŸ’¬ Recommend **context-aware reviews**.
* ğŸ›’ Help users **make informed shopping decisions** faster and smarter.

---

## ğŸ§© **Key Features**

| Area                        | Feature                           | Tool/Framework                          |
| --------------------------- | --------------------------------- | --------------------------------------- |
| ğŸ’¾ **Data Handling**        | Raw â†’ Processed â†’ Split           | Pandas, Scikit-learn                    |
| ğŸ§  **Modeling**             | Itemâ€“Item Collaborative Filtering | Custom Python module                    |
| ğŸ“ˆ **Experiment Tracking**  | Run tracking & model registry     | **MLflow**                              |
| ğŸŒ **Serving**              | REST API with Prometheus metrics  | **FastAPI + Prometheus Instrumentator** |
| ğŸ“Š **Monitoring**           | Dashboards and alerting           | **Grafana + Prometheus**                |
| âš™ï¸ **Data Drift Detection** | Report generation                 | **Evidently AI**                        |
| ğŸ³ **Containerization**     | Multi-service stack               | **Docker Compose**                      |
| ğŸ§ª **CI/CD & QA**           | Automated linting & testing       | **GitHub Actions**, Pre-commit          |
| â˜ï¸ **Cloud Integration**    | Hosted on AWS EC2                 | **AWS Cloud Infrastructure**            |

---

## ğŸ§± **Architecture Overview**

### ğŸ§­ End-to-End Pipeline

```mermaid
flowchart LR
  A[Raw Amazon Reviews ğŸ—‚ï¸] --> B[Data Cleaning ğŸ§¹]
  B --> C[Itemâ€“Item CF Model ğŸ§ ]
  C --> D[Evaluation: Recall@K, nDCG@K ğŸ“Š]
  C --> E[MLflow Tracking & Registry ğŸ§¾]
  C --> F[FastAPI Inference API âš™ï¸]
  F --> G[Prometheus Metrics ğŸ“ˆ]
  G --> H[Grafana Dashboards ğŸ“Š]
  B --> I[Evidently Drift Report ğŸ”]
  I --> H
```
## ğŸ§  System Architecture

![System Architecture](images/mlops_pipeline.svg)

[View full MLOps Pipeline diagram](images/mlops_pipeline.svg)
---

## ğŸ“‚ **Repository Structure**

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py                  # FastAPI App
â”‚   â”œâ”€â”€ train.py                # Model Training + MLflow Registration
â”‚   â”œâ”€â”€ evaluate.py             # Evaluation Metrics
â”‚   â””â”€â”€ ml/
â”‚       â”œâ”€â”€ recommenders/
â”‚       â”‚   â””â”€â”€ item_item.py    # Itemâ€“Item Collaborative Filtering
â”‚       â””â”€â”€ eval/
â”‚           â”œâ”€â”€ metrics.py      # recall@K, nDCG@K, coverage
â”‚           â””â”€â”€ eval_dataset.py # leave-one-out split generator
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ generate_drift.py
â”‚   â”œâ”€â”€ evidently_app.py
â”‚   â””â”€â”€ evidently_report.html
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ prometheus/prometheus.yml
â”‚   â”œâ”€â”€ grafana-dashboards/
â”‚   â””â”€â”€ grafana-provisioning/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ splits/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CONTRIBUTION.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .pre-commit-config.yaml
â””â”€â”€ README.md
```

---

## ğŸ“¦ **Quick Start**

### ğŸ§° 1. Clone & Setup

```bash
git clone https://github.com/YourOrg/product-review-analyzer.git
cd product-review-analyzer

# create environment
python -m venv .venv
source .venv/bin/activate     # (Windows: .venv\Scripts\activate)

# install dependencies
pip install -r requirements.txt

# activate pre-commit hooks
pre-commit install
```

### ğŸ§  2. Train and Track Model

```bash
mlflow server --host 0.0.0.0 --port 5000
python src/train.py
```

Access MLflow UI â†’ [http://localhost:5000](http://localhost:5000)
Latest model: **`product-recommender:v1.0`**

---

### âš¡ 3. Run the API Locally

```bash
make dev
# OR manually:
uvicorn src.api:app --host 0.0.0.0 --port 8000
```

Endpoints:

* `/docs` â†’ interactive FastAPI Swagger UI
* `/health` â†’ health check
* `/metrics` â†’ Prometheus metrics

Example:

```bash
curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{"user_id": 123, "k": 10}'
```
![FAST-API](images/fast-api.jpg)
---

### ğŸ§  4. Run Monitoring Stack

```bash
docker compose up --build
```

| Service         | URL                                                      | Default Login |
| --------------- | -------------------------------------------------------- | ------------- |
| API             | [http://localhost:8000/docs](http://localhost:8000/docs) | â€”             |
| Prometheus      | [http://localhost:9090](http://localhost:9090)           | â€”             |
| Grafana         | [http://localhost:3000](http://localhost:3000)           | admin / admin |
| Evidently Drift | [http://localhost:7000](http://localhost:7000)           | â€”             |

---

## ğŸ“ˆ **Evaluation**

We measure:

* âœ… **Recall@K** â†’ true item in top-K?
* âœ… **nDCG@K** â†’ discounted gain for correct ranking
* âœ… **Catalog Coverage** â†’ % of unique items recommended

Run manually:

```bash
python -m src.evaluate --data-dir data/processed --k 10
```

---

## ğŸ§¾ **MLflow Model Registry**

Tracked & versioned experiments with MLflow.

| Model                 | Version | Stage      | URI                                                              |
| --------------------- | ------- | ---------- | ---------------------------------------------------------------- |
| `product-recommender` | v1.0    | Production | [http://localhost:5000/#/models](http://localhost:5000/#/models) |

To start MLflow tracking server:

```bash
mlflow server --host 0.0.0.0 --port 5000
```

---

## ğŸ“Š **Monitoring with Prometheus + Grafana**

* Prometheus scrapes `/metrics` from FastAPI.
* Grafana visualizes:

  * API latency
  * Requests per second
  * Prediction counts

ğŸ“¸ **Dashboard Snapshots:**
![Grafana 1](images/grafana-dashboard-1.png)
![Grafana 2](images/grafana-dashboard-2.png)

---

## ğŸ§® **Evidently (Data Drift Reports)**

Generate drift report:

```bash
make drift
```

Serve the dashboard:

```bash
make serve-drift
```

ğŸ‘‰ [http://localhost:7000](http://localhost:7000)

ğŸ“¸ Example:
![Drift Report](images/evidently_report_1.png)

---

## â˜ï¸ **Cloud Deployment**

### ğŸŒ©ï¸ AWS Integration

| Component     | AWS Service Used          | Purpose                  |
| ------------- | ------------------------- | ------------------------ |
| API Hosting   | **EC2**                   | Host FastAPI container   |
| Model Storage | **S3**                    | MLflow backend artifacts |
| Monitoring    | **CloudWatch (optional)** | Alerting / Logs          |

### ğŸ–¼ï¸ AWS Components

<p align="center">
  <img src="images/cloud-1.jpg" alt="EC2 Instance Setup" width="350"/>
  &nbsp;&nbsp;&nbsp;
  <img src="images/cloud-4.jpg" alt="S3 Bucket Overview" width="350"/>
</p>

See ğŸ‘‰ [images](images) for additional setup and configuration screenshots !


ğŸ”§ **How to Reproduce Cloud Setup:**

1. Launch EC2 instance (Ubuntu 22.04, t2.medium)
2. Install Docker + Docker Compose
3. Clone repo and run `docker compose up -d`
4. Access the live stack:

| Service    | Public URL                                                     |
| ---------- | -------------------------------------------------------------- |
| API Docs   | [http://13.60.193.55:8000/docs](http://13.60.193.55:8000/docs) |
| Grafana    | [http://13.60.193.55:3000](http://13.60.193.55:3000)           |
| Prometheus | [http://13.60.193.55:9090](http://13.60.193.55:9090)           |

---

## âš™ï¸ **Makefile Targets**

| Command            | Description                       |
| ------------------ | --------------------------------- |
| `make dev`         | Run FastAPI with hot-reload       |
| `make train`       | Train and register model          |
| `make drift`       | Generate Evidently drift report   |
| `make serve-drift` | Serve drift dashboard (port 7000) |
| `make stack-up`    | Bring up Docker monitoring stack  |
| `make stack-down`  | Stop Docker containers            |

---


Includes:

* Member names & ERP IDs
* Task allocation (data, model, infra, monitoring)
* Branch naming conventions (`feat/`, `fix/`, `infra/`)

---

## ğŸ§¹ **Pre-Commit Hooks**

âœ… Configured hooks:

* `trailing-whitespace`
* `end-of-file-fixer`
* `detect-secrets`
* `black` + `ruff` formatters

Run manually:

```bash
pre-commit run --all-files
```

---

## ğŸ§ª **GitHub CI/CD (Milestone Requirement)**

| Stage            | Description                            |
| ---------------- | -------------------------------------- |
| ğŸ§¼ Lint          | Check style via Ruff + Black           |
| ğŸ§  Test          | Run pytest (â‰¥80% coverage)             |
| ğŸ—ï¸ Build        | Docker image tagged with `$GITHUB_SHA` |
| ğŸ§ª Canary Deploy | Push image to canary env               |
| ğŸ©º Acceptance    | Test 5+ golden requests on canary      |

âœ… Defined in `.github/workflows/ci.yml`

---

## ğŸ§° **FAQ**

**Q:** Why UTF-16 in requirements.txt?
**A:** Some systems needed BOM-encoded format for compatibility; open with UTF-16 in editors if installation fails.

**Q:** How do I fix Docker permission issues on Windows?
**A:** Run PowerShell as Admin â†’ `wsl --update` â†’ restart Docker Desktop.

**Q:** Grafana dashboard not showing data?
**A:** Ensure Prometheus target (`/metrics`) is healthy at [http://localhost:9090/targets](http://localhost:9090/targets).

---

## ğŸ”® **Future Vision (LLMOps Stage 2)**

> â€œBeyond recommendations â€” we aim for intelligent conversations about products.â€ ğŸ§ ğŸ’¬

In Milestone-2, weâ€™ll enhance our system into a **multimodal LLMOps pipeline**:

* ğŸ¤– Generate **personalized product reviews** based on user history.
* ğŸ—£ï¸ Use **LLMs (like GPT-4 or Falcon)** for summarizing customer sentiment.
* ğŸ” Provide **context-aware recommendations** combining embeddings from text and structured data.
* ğŸ“¦ Deploy via **LangChain + FastAPI + MLflow Serving** with real-time drift alerts.

**Use Cases:**

* ğŸ›ï¸ Smart shopping assistants that summarize reviews.
* ğŸ’¬ Automated brand insight generation.
* ğŸ“ˆ Continuous model retraining triggered by drift reports.

---

## ğŸªª **License & Compliance**

* ğŸ“œ **License:** MIT License â€” see `LICENSE`
* ğŸ¤ **Code of Conduct:** Contributor Covenant â€” `CODE_OF_CONDUCT.md`
* ğŸ§© **Dependency Scan:** `pip-audit` integrated (fails build on critical CVEs)

---

## ğŸ **Known Issues / TODOs**

* [ ] Fix Dockerfile app entry path â†’ `src.api:app`
* [ ] Validate all import paths in `train.py`
* [ ] Add additional unit tests for drift metrics
* [ ] Integrate GitHub container registry publishing

---

## âœ¨ **Screenshots**

| Component       | Preview                                      |
| --------------- | -------------------------------------------- |
| ğŸ³ Docker Setup | ![Docker Setup](images/docker-setup.png)     |
| ğŸ“ˆ Grafana      | ![Grafana 3](images/grafana-dashboard-3.jpg) |
| ğŸ§® MLflow       | ![MLflow](images/mlflow-1.png)               |
| ğŸ” Evidently    | ![Drift](images/evidently_report_2.png)      |

---

## ğŸŒŸ **Team**

| Name             | ERP ID | Role                                    |
| ---------------- | ------ | --------------------------------------- |
| **Zuha Aqib**    | 26106  | Team Lead â€” Data Pipeline & Model Training + CI/CD |
| **Maham Junaid** | 26909  | Cloud Integration & Monitoring setup    |
| **Maryam Ihsan** | 27152  | Evaluation & API Documentation    |
| **Muhammad Haaris** | 27083  | Data Pipeline & Model Training + CI/CD  |

---


## ğŸ§© Task Breakdown and Contributions

| Member           | Primary Responsibilities                       | Details of Work Done                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ---------------- | ---------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Zuha Aqib**    | Data Pipeline, Model Training, and CI/CD | <ul><li>Led data cleaning and preprocessing of Amazon reviews dataset</li><li>Implemented core data pipeline architecture</li><li>Co-developed **Itemâ€“Item Collaborative Filtering** algorithm</li><li>Implemented GitHub Actions workflow for CI/CD pipeline</li><li>Set up automated testing and linting checks</li><li>Created data validation and model testing workflows</li><li>Managed model versioning and artifact tracking</li><li>Implemented automated deployment pipelines</li></ul> |
| **Muhammad Haaris** | Data Pipeline, Model Training, and CI/CD | <ul><li>Co-developed data preprocessing and cleaning workflows</li><li>Implemented train-test split methodology</li><li>Enhanced **Itemâ€“Item Collaborative Filtering** implementation</li><li>Set up Docker containerization for model training</li><li>Configured CI/CD pipelines for model deployment</li><li>Implemented automated model retraining workflows</li><li>Created data validation checks</li><li>Set up monitoring for model training pipelines</li></ul> |
| **Maham Junaid** | Cloud Integration & API Documentation | <ul><li>Implemented AWS EC2 instance setup for model deployment</li><li>Configured S3 buckets for data and model storage</li><li>Set up CloudWatch monitoring for model performance</li><li>Created comprehensive FastAPI documentation</li><li>Developed API schema and example cURL commands</li><li>Implemented automated API testing</li><li>Created cloud infrastructure documentation</li><li>Set up cloud-based monitoring dashboards</li></ul> |
| **Maryam Ihsan** | Cloud Integration & API Documentation | <ul><li>Configured AWS Lambda functions for serverless operations</li><li>Implemented automated cloud deployment scripts</li><li>Created cloud service integration documentation</li><li>Enhanced FastAPI documentation with detailed examples</li><li>Developed comprehensive API testing suite</li><li>Created cloud deployment guides in README.md</li><li>Documented cloud service interactions</li><li>Implemented cloud resource monitoring</li></ul> |

---

## ğŸŒ¿ Branch-Naming Convention

| Branch Name                        | Prefix Category           | Purpose / Description                                                                                              |
| ---------------------------------- | ------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **`fix/structure`**                | `fix/`                    | Minor structural fixes and directory cleanup after initial setup (refined imports, paths, and relative structure). |
| **`infra/app-setup`**              | `infra/`                  | Configured application infrastructure â€” FastAPI service wiring, environment variables, and app-level organization. |
| **`infra/bootstrap-setup`**        | `infra/`                  | Initial repository bootstrap: virtual environment, Makefile, requirements, and local project scaffolding.          |
| **`infra/cloud-integration`**      | `infra/`                  | Cloud integration setup â€” connecting Dockerized services with cloud endpoints (planned deployment stage).          |
| **`ml-workflow-monitoring-setup`** | `ml-workflow/` *(custom)* | Integrated ML workflow monitoring â€” Prometheus, Grafana dashboards, and MLflow logging integration.                |
| **`main`**                         | â€”                         | Stable release branch for milestone submissions and final presentation.                                            |


## ğŸ§‘â€ğŸ’» **Contribution Guide**

See ğŸ‘‰ [CONTRIBUTION.md](CONTRIBUTION.md)
updated information can be found in CONTRIBUTION.md

## ğŸŒŸ **Bonus Features**

| Bonus Feature                                | Description                                                                                                         | Status        |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ------------- |
| ğŸ³ *Docker Compose Multi-Service Setup*    | Separate containers/services for *App, **DB, **Prometheus, and **Grafana*. Supports dev/test/prod profiles. | âœ… Implemented |
| âš¡ *GPU-enabled Image & Self-Hosted Runner* | CI/CD pipeline uses GPU-enabled Docker image for model training and integrates with self-hosted GitHub runner.      | â–“â–“â–‘â–‘â–‘ 40%     |
| ğŸ—ï¸ *IaC Sample (Terraform / MinIO)*       | Example scripts to spin up local object storage (MinIO) and other resources via Terraform or other IaC tools.       | â–“â–‘â–‘â–‘â–‘ 20%     |
| ğŸ“Š *End-to-End Load Test Script (k6)*      | Load testing scripts with latency SLO assertions for the deployed services.                                         | â–“â–‘â–‘â–‘â–‘ 30%     |
| ğŸ›¡ï¸ *Dependency Vulnerability Scan*        | pip-audit checks for critical CVEs and fails build if found.                                                      | âœ… Implemented |
| ğŸ“¦ *Git LFS (Large File Support)*          | Optional: Not required for this project due to dataset size, but pipeline supports it.                              | âœ… Implemented/ Optional   |

all remaining will be fully implemented in stage 2 !!!

## ğŸ’¡ **Tag & Submission**

âœ… Push with tag:

```bash
git tag v1.0-milestone1
git push origin v1.0-milestone1
```


---

### ğŸ’¬ *â€œFrom product reviews to product intelligence â€” the journey starts here.â€* ğŸ§ ğŸ’¬âœ¨

Developed with â¤ï¸ by Team **Product Review Analyzer**

---
